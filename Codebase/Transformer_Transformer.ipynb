{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab68325f-539e-427e-acc8-4e2a7208cb79",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08c6cd6-9a61-4e4a-bed1-2d8954762606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa #this had to be installed from github\n",
    "import tensorflow.keras as keras\n",
    "import sys\n",
    "import pickle, random, string\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path #for nicely dealing with Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b741a2-a3bf-407e-98a3-92e9ce619443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/Extrapolation-Exploration/Codebase/Codebase',\n",
       " '/opt/conda/lib/python39.zip',\n",
       " '/opt/conda/lib/python3.9',\n",
       " '/opt/conda/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/opt/conda/lib/python3.9/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ugly patch becasue idk how to make this propperly work\n",
    "sys.path[0] += '/Codebase'\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a5cba5-fec0-4ab4-9415-2c525412a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:21:09.118372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-30 07:21:09.118431: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-30 07:21:09.118458: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-lak3r): /proc/driver/nvidia/version does not exist\n",
      "2022-07-30 07:21:09.118877: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#my classes\n",
    "#from testClass import *\n",
    "from transformerClasses import *\n",
    "from embeddingClasses import *\n",
    "from lstmClasses import *\n",
    "from resourceFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581ca25-2682-46f3-82ac-29a429def22e",
   "metadata": {},
   "source": [
    "# Loading Outer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f0d558-e077-4bf7-8aec-e576ad566c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../.ipynb_checkpoints'), PosixPath('../saved-models'), PosixPath('../Qualifying-Exam-Writings'), PosixPath('../Codebase'), PosixPath('../data'), PosixPath('../.git')]\n"
     ]
    }
   ],
   "source": [
    "# setting up the pathlib stuff \n",
    "path = Path('..')\n",
    "print([x for x in path.iterdir() if x.is_dir()])\n",
    "\n",
    "path = path / 'saved-models'\n",
    "outPath = path / 'OuterTransformer'\n",
    "\n",
    "encPathJson = outPath / 'encoder_len53.json'\n",
    "decPathJson = outPath / 'decoder_len53.json'\n",
    "encPathH5 = outPath / 'encoder_len53.h5'\n",
    "decPathH5 = outPath / 'decoder_len53.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db76839f-7921-49ad-a704-250efc9178ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with encPathJson.open() as encFile, decPathJson.open() as decFile:\n",
    "    encJson = encFile.read()\n",
    "    decJson = decFile.read()\n",
    "    \n",
    "outer_encoder = keras.models.model_from_json(encJson, \n",
    "                                            custom_objects={\"PositionEmbedding\":OuterPositionEmbedding,\n",
    "                                                            \"TransformerBlock\":OuterTransformerBlock,\n",
    "                                                            \"MaskedTokenAndPositionEmbedding\": OuterMaskedTokenAndPositionEmbedding, \n",
    "                                                            \"MaskedTransformerBlock\":OuterMaskedTransformerBlock})\n",
    "outer_decoder = keras.models.model_from_json(decJson, \n",
    "                                             custom_objects={\"PositionEmbedding\":OuterPositionEmbedding,\n",
    "                                                             \"TransformerBlock\":OuterTransformerBlock,\n",
    "                                                             \"MaskedTokenAndPositionEmbedding\": OuterMaskedTokenAndPositionEmbedding, \n",
    "                                                             \"MaskedTransformerBlock\":OuterMaskedTransformerBlock})\n",
    "outer_encoder.load_weights(encPathH5)\n",
    "outer_decoder.load_weights(decPathH5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931e804-ff20-4ed2-9039-12e747ac874c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Traning and Testing Data and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84b176a-7dac-470f-b7c5-b1666f086329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "\n",
    "# corpus = np.loadtxt(sys.argv[1], dtype=object)\n",
    "# trainingSet = np.loadtxt(sys.argv[2], dtype=object)\n",
    "# testingSet  = np.loadtxt(sys.argv[3], dtype=object)\n",
    "\n",
    "\n",
    "#corpus = np.loadtxt(sys.argv[1], dtype=object)\n",
    "corpus = (Path('..') / 'data' / 'len5_10000-train.txt' ).open() #open('../data/len5_10000-train.txt')\n",
    "corpus = np.loadtxt(corpus, dtype=object)\n",
    "\n",
    "trainingSet = (Path('..') / 'data' / 'SG-10-train.txt').open()\n",
    "testingSet  = (Path('..') / 'data' / 'SG-10-test.txt').open()\n",
    "\n",
    "trainingSet = np.loadtxt(trainingSet, dtype=str)\n",
    "testingSet  = np.loadtxt(testingSet, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e076b45-093a-4e52-a446-65ab2143dd20",
   "metadata": {},
   "source": [
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69a4715-ded5-465e-91ee-2315e7d50c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create embeddings ---\n",
    "X, Y, preY, postY, mapping = letter_to_int(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562e0edf-1135-428e-bfc7-ae093557b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 10 indices from the coprus WOR\n",
    "corIdx = np.random.randint(0,high=len(corpus),size=20)\n",
    "#I could probably just do a np array of size 10000 \n",
    "corIdx = np.random.choice(corIdx,size=10,replace=False)\n",
    "\n",
    "outer_x = X[corIdx]\n",
    "outer_preY = preY[corIdx]\n",
    "outer_postY = postY[corIdx]\n",
    "\n",
    "outer_embeddings = outer_encoder.predict(outer_x)\n",
    "\n",
    "trainingSet_int = letter_to_int(trainingSet)[0]\n",
    "\n",
    "testingSet_int = letter_to_int(testingSet)[0]\n",
    "\n",
    "inner_x = np.array([outer_embeddings[trainingSet_int[x]-1] for x in range(len(trainingSet))]) #200 comes from the trainingSet \n",
    "inner_x_testing = np.array([outer_embeddings[testingSet_int[x]-1] for x in range(len(testingSet))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f8ffa9c-fa24-4e3b-a319-0f1ad4321f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[ 4.18494863e-04,  6.78124465e-03, -2.14721948e-01, ...,\n",
       "          1.99231959e-04,  3.25998553e-04, -2.98861414e-05],\n",
       "        [-2.29592668e-04, -7.73117132e-03, -1.37685519e-02, ...,\n",
       "         -6.93213660e-04, -4.64366924e-04, -4.79313021e-04],\n",
       "        [ 9.29229427e-04,  4.34680609e-03,  2.06333667e-01, ...,\n",
       "          6.44610147e-04,  6.56995748e-04,  1.62306370e-03],\n",
       "        [ 6.60396763e-04,  9.51866619e-03, -1.17494889e-01, ...,\n",
       "          2.48235068e-04,  3.81024234e-04, -6.11261930e-05],\n",
       "        [-9.54381481e-04, -1.86389906e-03,  1.57343432e-01, ...,\n",
       "         -1.56216277e-03, -1.26708800e-03, -2.34887935e-03]],\n",
       "\n",
       "       [[-1.41955970e-04,  2.33728415e-03,  1.07111841e-01, ...,\n",
       "         -2.34974505e-04, -1.03536964e-04, -6.67184126e-04],\n",
       "        [-1.41432160e-04, -9.72443819e-03, -1.65956140e-01, ...,\n",
       "         -8.07623030e-04, -4.87067067e-04, -4.52169013e-04],\n",
       "        [-5.38082153e-04,  9.21202824e-04,  3.41728419e-01, ...,\n",
       "         -6.03584922e-04, -3.82332539e-04, -3.37256643e-04],\n",
       "        [ 4.06475912e-04,  2.58652866e-03, -2.16454521e-01, ...,\n",
       "          3.82749160e-04,  4.08304972e-04,  1.20600965e-03],\n",
       "        [-1.42386090e-03, -3.19728372e-03,  1.72611907e-01, ...,\n",
       "         -1.69788382e-03, -1.35747192e-03, -1.65059057e-03]],\n",
       "\n",
       "       [[-7.00523378e-06, -2.78481399e-03, -1.10988244e-01, ...,\n",
       "          1.20468849e-05,  1.66979065e-04,  4.57445683e-04],\n",
       "        [ 3.23608459e-04, -1.54542294e-03,  1.59442306e-01, ...,\n",
       "         -3.21962725e-04, -9.96387535e-05, -1.01410924e-03],\n",
       "        [ 1.38475024e-03, -3.93166067e-03,  1.91703752e-01, ...,\n",
       "          9.50946414e-04,  9.46066692e-04,  1.76695595e-03],\n",
       "        [ 6.50787260e-04,  3.84328607e-03,  2.17011169e-01, ...,\n",
       "          5.50715660e-04,  6.86581945e-04,  2.85269110e-04],\n",
       "        [-9.83223086e-04, -1.49411312e-03,  1.30411014e-01, ...,\n",
       "         -1.57713483e-03, -1.27967447e-03, -2.32044002e-03]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need testing inner_postY_testing\n",
    "dog = np.zeros((1,5,300))\n",
    "dog.shape\n",
    "np.concatenate((dog, inner_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7901256f-81b6-46eb-b83c-b7c8162d96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make inner_postY and outer_postY\n",
    "dog = np.zeros((1,5,300))\n",
    "inner_preY = np.array([np.concatenate((dog,inner_x[i])) for i in range(len(inner_x))])\n",
    "inner_postY = np.array([np.concatenate((inner_x[i],dog)) for i in range(len(inner_x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "192829b2-ae40-4757-a66e-ea351909a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "       [[ 1.84265140e-04,  7.35766767e-03, -2.20841244e-02, ...,\n",
       "          1.48633248e-04,  3.22618755e-04,  2.83883797e-04],\n",
       "        [-2.53078120e-04, -9.76604782e-03, -1.62564769e-01, ...,\n",
       "         -8.66995077e-04, -5.40178444e-04, -4.89160651e-04],\n",
       "        [ 1.44601462e-03, -3.76403681e-03,  2.00419426e-01, ...,\n",
       "          1.02494296e-03,  1.01020944e-03,  1.83222885e-03],\n",
       "        [-3.94978997e-06,  5.34896692e-03,  1.92975059e-01, ...,\n",
       "         -2.26038144e-04, -8.56490806e-05, -7.24542071e-04],\n",
       "        [-9.48938134e-04, -1.37287588e-03,  1.41620308e-01, ...,\n",
       "         -1.53224939e-03, -1.24288176e-03, -2.30022147e-03]],\n",
       "\n",
       "       [[-1.17467891e-03,  2.63808761e-05,  1.40648991e-01, ...,\n",
       "         -7.50721374e-04, -5.27141499e-04, -4.46149090e-04],\n",
       "        [ 1.16824126e-03, -1.88768539e-03, -3.66218686e-02, ...,\n",
       "          2.90436496e-04,  5.12507861e-04,  1.35604921e-03],\n",
       "        [ 7.15472735e-04,  2.18412839e-03,  2.22868919e-01, ...,\n",
       "          7.41530268e-04,  7.97074055e-04,  1.16321875e-03],\n",
       "        [ 1.20088446e-03,  2.47074314e-03,  1.80715695e-01, ...,\n",
       "          8.73425801e-04,  9.67862259e-04,  8.90907482e-04],\n",
       "        [-4.18924494e-04, -2.88699148e-03,  1.62421808e-01, ...,\n",
       "         -7.27019622e-04, -4.47390717e-04, -1.34341093e-03]],\n",
       "\n",
       "       [[-1.41955970e-04,  2.33728415e-03,  1.07111841e-01, ...,\n",
       "         -2.34974505e-04, -1.03536964e-04, -6.67184126e-04],\n",
       "        [-1.41432160e-04, -9.72443819e-03, -1.65956140e-01, ...,\n",
       "         -8.07623030e-04, -4.87067067e-04, -4.52169013e-04],\n",
       "        [-5.38082153e-04,  9.21202824e-04,  3.41728419e-01, ...,\n",
       "         -6.03584922e-04, -3.82332539e-04, -3.37256643e-04],\n",
       "        [ 4.06475912e-04,  2.58652866e-03, -2.16454521e-01, ...,\n",
       "          3.82749160e-04,  4.08304972e-04,  1.20600965e-03],\n",
       "        [-1.42386090e-03, -3.19728372e-03,  1.72611907e-01, ...,\n",
       "         -1.69788382e-03, -1.35747192e-03, -1.65059057e-03]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing postY and preY\n",
    "dog = np.zeros((1,5,300))\n",
    "dog.shape\n",
    "np.concatenate((dog, inner_x_testing[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efbb9138-07ea-49a8-b5ed-53516bb49c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = np.zeros((1,5,300))\n",
    "inner_preY_testing = np.array([np.concatenate((dog,inner_x_testing[i])) for i in range(len(inner_x_testing))])\n",
    "inner_postY_testing = np.array([np.concatenate((inner_x_testing[i],dog)) for i in range(len(inner_x_testing))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52e72ace-cf61-447e-9682-446458dc9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Make start and stop tokens ---\n",
    "s_s = {\"start\":[1,0],\"stop\":[0,1], \"none\":[0,0]}\n",
    "pre_start = np.zeros((inner_x.shape[0], 4, 2))\n",
    "post_stop = np.zeros((inner_x.shape[0], 4, 2))\n",
    "pre_start[:,0,:] = s_s[\"start\"]\n",
    "post_stop[:,3,:] = s_s[\"stop\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39575a76-d9b0-4973-9d01-bb0364ae2648",
   "metadata": {},
   "source": [
    "# Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b28494e-0a80-43ee-9492-7cf0279ffea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7851feed-f1a7-40e6-8939-6a07aeec1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model parameters ---\n",
    "length = 10\n",
    "padded_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "340891ff-47e4-497b-a7fd-d5632c3500de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we are making these the same, but they don't -have- to be!\n",
    "input_length = padded_length\n",
    "output_length = padded_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c27afcad-11c2-47e5-9683-a6b117a2fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary sizes...\n",
    "encoder_vocab_size = 30 # a, b, c, ... z, start, stop, STARTSENTENCE, STOPSENTENCE\n",
    "decoder_vocab_size = 30 # a, b, c, ... z, start, stop, STARTSENTENCE, STOPSENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70191bb5-e7ee-40b4-9604-82f0d76f84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the gestalt, context representations...\n",
    "embed_dim = 128  # Embedding size for each token (enc/dec inputs already embedded)\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "stack = 1\n",
    "wd = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfc44d29-2666-41fd-980b-130319f526d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 300\n",
    "BATCH_SIZE  = 50\n",
    "EPOCHS      = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956a69e-9286-4007-bf02-5a3314d5154e",
   "metadata": {},
   "source": [
    "# Construct Inner encoder/decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4307384-5982-4e04-9c59-f4e6bbea2838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:22:37.044986: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_2929\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:17\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 50\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-07-30 07:22:37.082942: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "# --- Construct inner encoder/decoder ---\n",
    "with strategy.scope():\n",
    "    # Encoder\n",
    "    encoder_input = keras.layers.Input(shape=(None,) + inner_x.shape[2:], name=\"inner_enc_token\")\n",
    "\n",
    "    encoder_reshape = keras.layers.Reshape((-1,1500))(encoder_input)\n",
    "\n",
    "    encoder_embedding = keras.layers.Dense(embed_dim)(encoder_reshape)\n",
    "\n",
    "    encoder_mask_pos_embedding = InnerMaskedPositionEmbedding(maxlen=input_length,\n",
    "                                                         embed_dim=encoder_embedding.shape[-1])(encoder_embedding)\n",
    "\n",
    "    encoder_state = InnerTransformerBlock(embed_dim=encoder_embedding.shape[-1],\n",
    "                                     num_heads=num_heads,\n",
    "                                     ff_dim=ff_dim)(encoder_mask_pos_embedding)\n",
    "    encoder_model = keras.Model(encoder_input,encoder_state,name=\"InnerEncoder\")\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = keras.layers.Input(shape=(None,) + inner_preY.shape[2:], name=\"inner_dec_token\")\n",
    "\n",
    "    decoder_context_input = keras.layers.Input(shape=encoder_state.shape[1:], name='inner_enc_state')\n",
    "\n",
    "    decoder_reshape = keras.layers.Reshape((-1,1500))(decoder_input)\n",
    "\n",
    "    decoder_startstop = keras.layers.Input(shape=(None, 2), name=\"dec_start/stop\")\n",
    "\n",
    "    decoder_inputs = [decoder_context_input, decoder_input, decoder_startstop]\n",
    "\n",
    "    decoder_concat = keras.layers.Concatenate()([decoder_reshape, decoder_startstop])\n",
    "\n",
    "    decoder_embedding = keras.layers.Dense(embed_dim)(decoder_concat)\n",
    "\n",
    "    decoder_mask_pos_embedding = InnerMaskedPositionEmbedding(maxlen=inner_preY.shape[1],\n",
    "                                                         embed_dim=decoder_embedding.shape[-1])(decoder_embedding)\n",
    "\n",
    "    decoder_block = InnerMaskedTransformerBlock(embed_dim=decoder_mask_pos_embedding.shape[-1],\n",
    "                                           num_heads=num_heads,\n",
    "                                           ff_dim=ff_dim)\n",
    "\n",
    "    decoder_hidden_output = decoder_block([decoder_mask_pos_embedding, decoder_context_input])\n",
    "\n",
    "    x = keras.layers.Dense(inner_postY.shape[2]*embed_dim)(decoder_hidden_output)\n",
    "\n",
    "    inner_output_reshape = keras.layers.Reshape((-1,inner_postY.shape[-2],embed_dim))(x)\n",
    "\n",
    "    decoder_dense_t1 = keras.layers.Dense(inner_postY.shape[-1], activation='linear', name=\"output_token\")(inner_output_reshape)\n",
    "\n",
    "    decoder_dense_startstop = keras.layers.Dense(2, activation='sigmoid', name=\"start/stop\")(decoder_hidden_output)\n",
    "\n",
    "    decoder_outputs = [decoder_dense_t1, decoder_dense_startstop]\n",
    "\n",
    "    decoder_model = keras.Model(decoder_inputs,decoder_outputs,name=\"InnerDecoder\")\n",
    "    \n",
    "    # Tie encoder and decoder into one model\n",
    "    #with strategy.scope():\n",
    "    #model = keras.Model([encoder_input]+ decoder_inputs, decoder_outputs)\n",
    "    coupled_inputs = [keras.layers.Input(encoder_model.inputs[0].shape[1:]),\n",
    "                      keras.layers.Input(decoder_model.inputs[1].shape[1:]),\n",
    "                      keras.layers.Input(decoder_model.inputs[2].shape[1:])]                     \n",
    "    coupled_outputs = decoder_model([encoder_model(coupled_inputs[0])] + coupled_inputs[1:])\n",
    "    model = keras.Model(coupled_inputs, coupled_outputs)\n",
    "\n",
    "    # --- Compile and fit model ---\n",
    "    model.compile(loss = [keras.losses.MSE,keras.losses.binary_crossentropy],\n",
    "               optimizer=keras.optimizers.Adam(),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "    model_input = {\"inner_enc_token\":inner_x, \"inner_dec_token\":inner_preY,\n",
    "                         \"dec_start/stop\":pre_start}\n",
    "    model_target = {\"output_token\":inner_postY, \"start/stop\": post_stop}\n",
    "\n",
    "    #with strategy.scope():\n",
    "    history = model.fit([inner_x,inner_preY, pre_start], [inner_postY,post_stop],\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         epochs=EPOCHS,\n",
    "                         verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa3b94-0716-497c-997b-c8a47bbcd24d",
   "metadata": {},
   "source": [
    "# Get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b73f48-64f6-4ef2-b17d-de0b49f529c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Get accuracy ---\n",
    "with strategy.scope():\n",
    "    word_acc_arr = []\n",
    "    letter_acc_arr = []\n",
    "    for m in range(100):\n",
    "        #get the context\n",
    "        context = encoder_model.predict(inner_x_testing[m:m+1]) \n",
    "        #without teacher forcing\n",
    "\n",
    "        input_tokens = np.zeros_like(inner_preY_testing[m:m+1])\n",
    "\n",
    "        input_start = np.zeros_like(pre_start[m:m+1])\n",
    "\n",
    "        input_start[0,0:1,:] = pre_start[0,0:1,:]\n",
    "\n",
    "        for i in range(0,3):\n",
    "\n",
    "            output_tokens = decoder_model.predict([context, input_tokens, input_start])\n",
    "\n",
    "            input_tokens[:,i+1:i+2,:,:] = output_tokens[0][:,i:i+1,:,:] #replace on input_tokens timestep\n",
    "            input_start[:,i+1:i+2,:] = output_tokens[1][:,i:i+1,:]\n",
    "            #context = output_tokens[2:4]\n",
    "        output_tokens = decoder_model.predict([context, input_tokens, input_start])\n",
    "\n",
    "        arr = []\n",
    "\n",
    "        for k in range(3):\n",
    "            context = output_tokens[0][0][k:k+1,:,:]\n",
    "            actual_context = inner_postY_testing[m][k:k+1,:,:]\n",
    "            # Use this if you just want to test the outer decoder...\n",
    "            context = actual_context\n",
    "            i=0\n",
    "            tokens = np.zeros_like(outer_preY[0:1])\n",
    "            tokens[0:1,0:1] = outer_preY[0:1,0:1] # Start only...\n",
    "\n",
    "            for j in range(5): #ouput length is 5+1\n",
    "                result = np.argmax(outer_decoder.predict([tokens,context]),-1)\n",
    "                tokens[0:1,j+1:j+2] = result[0:1, j:j+1]\n",
    "            result = np.argmax(outer_decoder.predict([tokens,context]),-1)\n",
    "            arr.append(int_to_letter(result, mapping)[0])\n",
    "\n",
    "        output = np.asarray(arr)\n",
    "\n",
    "        check = int_to_letter(outer_postY[testingSet_int[m]-1], mapping)\n",
    "\n",
    "        word_acc_arr.append(word_accuracy(output, check))\n",
    "        letter_acc_arr.append(letter_accuracy(output, check))\n",
    "\n",
    "# use `model.metrics_names` to get indices for accuracy:\n",
    "print('-----------------------------')\n",
    "print('''   Generalization Accuracy\n",
    "-----------------------------\n",
    "word_accuracy: %f\n",
    "letter_accuracy: %f\n",
    "'''%(sum(word_acc_arr) / len(word_acc_arr) * 100, sum(letter_acc_arr) / len(letter_acc_arr) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fe12d-55ad-457a-a09b-575128bceb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
